{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, random\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "np.random.seed(0)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "def my_covar(x, y):\n",
    "    return my_mean(x * y) - my_mean(x) * my_mean(y)\n",
    "\n",
    "def my_var(x):\n",
    "    return np.nansum( (np.array(x) - my_mean(x)) ** 2) / len(x)\n",
    "    \n",
    "def my_mean(x):\n",
    "    return np.nansum(x) / len(x)\n",
    "\n",
    "def my_corr(x, y):\n",
    "    numerator = my_covar(x, y)\n",
    "    denom = np.sqrt(my_var(x)) * np.sqrt(my_var(y))\n",
    "    return numerator / denom\n",
    "\n",
    "def custom_r2(true, pred):\n",
    "    rss = np.nansum((true - pred) ** 2)\n",
    "    tss = np.nansum((true - my_mean(true)) ** 2)\n",
    "    return 1 - (rss / tss)\n",
    "\n",
    "def plot_price_over_time(df, symbol):\n",
    "    fig, axs = plt.subplots(3, 1, figsize = (15, 9), sharex = True)\n",
    "    df = df[df[\"symbol\"] == symbol].sort_values(by = [\"date\"])\n",
    "    print(list(df))\n",
    "    axs[0].set_ylabel(\"Stock Price (USD)\")\n",
    "    axs[0].set_xlabel(\"Time\")\n",
    "    axs[0].plot(df.date, df.stockPrice, ls = \"--\", lw = 2, color = \"black\", alpha = 0.8, label = \"Price\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(df.date, df.marketCapitalization)\n",
    "    print(f\"{my_corr(df.stockPrice, df.marketCapitalization) = }\")\n",
    "    plt.show()\n",
    "\n",
    "def get_outlier_idxs(feature, feature_name):\n",
    "    \n",
    "    use_mad = True\n",
    "    use_quantile = False\n",
    "    ignore_pct = 0.01\n",
    "\n",
    "    if(use_mad):\n",
    "        magic_c = 0.6745\n",
    "        cutoff_value = 8.0 \n",
    "        mad = np.nanmedian(np.abs(feature - np.nanmedian(feature)))\n",
    "        mi_feature = (magic_c * (feature - np.nanmedian(feature))) / mad\n",
    "        outliers = np.where(np.abs(mi_feature) >= cutoff_value)[0]\n",
    "        print(f\"{feature_name} Found {len(outliers)} outliers out of {feature.shape[0]} -- {len(outliers) / feature.shape[0] * 100: .2f}%\")\n",
    "    \n",
    "\n",
    "    elif(use_quantile):\n",
    "        lower = np.nanquantile(feature, ignore_pct)\n",
    "        upper = np.nanquantile(feature, 1 - ignore_pct) \n",
    "        outliers = np.where((feature >= upper) | (feature <= lower))[0]\n",
    "        print(f\"{feature_name} Found {len(outliers)} outliers out of {feature.shape[0]} -- {len(outliers) / feature.shape[0] * 100: .2f}%\")\n",
    "\n",
    "    return outliers\n",
    "    \n",
    "x = [123, 4, 1, 2 ,4, 2]\n",
    "y = [1, 2, 3, 4, 5, 6]\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# print(my_var(x))\n",
    "# print(my_corr(x, y))\n",
    "\n",
    "# print(np.corrcoef(x, y))\n",
    "# print(r2_score(x, y))\n",
    "# print(custom_r2(x, y))\n",
    "# corr = covar(x, y) / std(x) * std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/lselig/selig-fa/finance/.data/evs_ratios.parquet\")\n",
    "# df[\"year\"] = pd.DatetimeIndex(df[\"date\"]).year\n",
    "# df = df[df.symbol.isin([\"AAPL\", \"GOOGL\", \"MSFT\", \"GME\", \"A\", \"QQQ\", \"AMZN\", \"TSLA\"])]\n",
    "# df = df[df.year >= 2015]\n",
    "df = df[(df.stockPrice >= 2) & (df.stockPrice <= 1000)]\n",
    "remove_me = []\n",
    "for col in list(df):\n",
    "    num_na = df[col].isna().sum().sum()\n",
    "    print(col, num_na)\n",
    "    if(num_na > 30000):\n",
    "        remove_me.append(col)\n",
    "\n",
    "df = df.drop(columns = remove_me)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# plt.scatter(df.stockPrice * df.numberOfShares, df.marketCapitalization)\n",
    "# plt.show()\n",
    "\n",
    "# plot_price_over_time(df, \"MSFT\")\n",
    "\n",
    "meta_cols = [\"year\", \"symbol\", \"date\", \"quarter\", \"cik\"]\n",
    "drop_me_experimental = [\"priceEarningsToGrowthRatio\", \"numberOfShares\", \n",
    "                        \"quickRatio\", \"daysOfSalesOutstanding\", \n",
    "                        \"effectiveTaxRate\", \"freeCashFlowOperatingCashFlowRatio\"]\n",
    "df = df.drop(columns = meta_cols)\n",
    "df = df.drop(columns = drop_me_experimental)\n",
    "features = df\n",
    "ignore_me = [\"buySellRatio\", \"totalBought\", \"totalSold\",\n",
    "             \"averageBought\", \"averageSold\", \"pPurchases\",\n",
    "             \"sSales\", \"purchases\", \"sales\"]\n",
    "# ignore_me = ignore_me + ignore_me_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_idxs = []\n",
    "majority_outliers = {}\n",
    "for i, feature in enumerate(features):\n",
    "    # print(f\"{feature = } -- {np.corrcoef(features[feature].values, labels)[0, 1]:.4f}\")\n",
    "    if(feature not in ignore_me):\n",
    "        result = get_outlier_idxs(features[feature].values, feature)\n",
    "        for idx in result:\n",
    "            if(idx not in majority_outliers):\n",
    "                majority_outliers[idx] = 1\n",
    "            else:\n",
    "                majority_outliers[idx] += 1\n",
    "\n",
    "        print(result)\n",
    "        outlier_idxs.append(result)\n",
    "\n",
    "lives = 3\n",
    "remove_me = []\n",
    "plt.hist(majority_outliers.values(), bins = 50)\n",
    "plt.show()\n",
    "for key in majority_outliers:\n",
    "    print(majority_outliers[key] >= lives, majority_outliers[key])\n",
    "    if(majority_outliers[key] >= lives):\n",
    "        remove_me.append(key)\n",
    "        \n",
    "# remove_me = set().union(*outlier_idxs)\n",
    "print(f\"Killing {len(remove_me)} rows out of {len(features)}\")\n",
    "bad_idx = list(remove_me)\n",
    "\n",
    "labels = df[\"stockPrice\"].values\n",
    "df = df.reset_index(drop = True)\n",
    "bad_df = df.index.isin(bad_idx)\n",
    "df = df[~bad_df]\n",
    "\n",
    "print(df.shape)\n",
    "labels = df.stockPrice\n",
    "features = df.drop(columns = [\"stockPrice\"])\n",
    "corr = features.corr()\n",
    "sns.heatmap(corr, annot = False, xticklabels=False, yticklabels=False)\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(2, 1, figsize = (15, 9))\n",
    "axs[0].scatter(df.stockPrice, df.marketCapitalization)\n",
    "# %matplotlib widget\n",
    "# plt.hist(df.stockPrice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"{feature = } -- {np.corrcoef(features[feature].values, labels)[0, 1]:.4f}\")\n",
    "    plt.scatter(features[feature], labels)\n",
    "    plt.show()\n",
    "    # if(feature not in ignore_me):\n",
    "    #     result = get_outlier_idxs(features[feature].values, feature)\n",
    "    #     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size = 0.8)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# print(y_train[:5])\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(y_test[:20].values)\n",
    "\n",
    "print(y_pred[:20])\n",
    "\n",
    "my_r2 = r2_score(y_test, y_pred)\n",
    "my_mae = mean_absolute_error(y_test, y_pred)\n",
    "my_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "my_mape = np.sqrt(mean_absolute_percentage_error(y_test, y_pred))\n",
    "print(f\"{my_r2 = }\")\n",
    "print(f\"{my_mae = }\")\n",
    "print(f\"{my_rmse = }\")\n",
    "print(f\"{my_mape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "%matplotlib inline\n",
    "plt.hist2d(y_test, y_pred, bins = 400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
